{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# PINNs for Alzheimer's Disease Modeling - Batch Runner\n",
        "\n",
        "This notebook automatically:\n",
        "1. Clones the repository\n",
        "2. Sets up the environment\n",
        "3. Runs all 8 models sequentially\n",
        "4. Displays individual and combined results\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Clone the Repository and Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/DebadityaHait/PINNs\n",
        "%cd PINNs\n",
        "\n",
        "# Install required packages\n",
        "%pip install torch numpy matplotlib pandas scipy seaborn\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Setup Environment and Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Add src directory to path for deepxdeAbeta imports\n",
        "sys.path.append('./src')\n",
        "\n",
        "# Create necessary directories if they don't exist\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# Check if deepxdeAbeta is accessible\n",
        "try:\n",
        "    import deepxdeAbeta.deepxde as dde\n",
        "    print(\"✅ deepxdeAbeta imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Error importing deepxdeAbeta: {e}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Define Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model_data(model_num):\n",
        "    \"\"\"Load model data from results directory\"\"\"\n",
        "    model_dir = f\"results/models/model{model_num}\"\n",
        "    \n",
        "    # Check if model directory exists\n",
        "    if not os.path.exists(model_dir):\n",
        "        print(f\"Model {model_num} directory not found: {model_dir}\")\n",
        "        return None\n",
        "    \n",
        "    # Load data\n",
        "    try:\n",
        "        info = pd.read_csv(f\"{model_dir}/info.dat\", sep='\\s+', header=None)\n",
        "        variables = pd.read_csv(f\"{model_dir}/variables.dat\", sep='\\s+', header=None)\n",
        "        loss = pd.read_csv(f\"{model_dir}/loss.dat\", sep='\\s+', header=None)\n",
        "        train = pd.read_csv(f\"{model_dir}/train.dat\", sep='\\s+', header=None)\n",
        "        test = pd.read_csv(f\"{model_dir}/test.dat\", sep='\\s+', header=None)\n",
        "        \n",
        "        # Load model weights if needed\n",
        "        model_file = f\"{model_dir}/nonneg_constr-35000.pt\"\n",
        "        if not os.path.exists(model_file):\n",
        "            model_file = f\"{model_dir}/nonneg_constr-50000.pt\"  # Model 8 uses 50000\n",
        "        \n",
        "        model_exists = os.path.exists(model_file)\n",
        "        \n",
        "        return {\n",
        "            \"info\": info,\n",
        "            \"variables\": variables,\n",
        "            \"loss\": loss,\n",
        "            \"train\": train,\n",
        "            \"test\": test,\n",
        "            \"model_file\": model_file if model_exists else None,\n",
        "            \"model_exists\": model_exists\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data for model {model_num}: {e}\")\n",
        "        return None\n",
        "\n",
        "def plot_loss_history(model_num, model_data):\n",
        "    \"\"\"Plot loss history for a model\"\"\"\n",
        "    if model_data is None or \"loss\" not in model_data:\n",
        "        print(f\"No loss data available for model {model_num}\")\n",
        "        return\n",
        "    \n",
        "    loss_df = model_data[\"loss\"]\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.semilogy(loss_df[0], loss_df[1], label='Loss')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'Model {model_num} Loss History')\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\", ls=\"-\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_parameter_evolution(model_num, model_data):\n",
        "    \"\"\"Plot parameter evolution for a model\"\"\"\n",
        "    if model_data is None or \"variables\" not in model_data:\n",
        "        print(f\"No variable data available for model {model_num}\")\n",
        "        return\n",
        "    \n",
        "    var_df = model_data[\"variables\"]\n",
        "    \n",
        "    # Assuming column 0 is iteration, and the rest are parameters\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i in range(1, len(var_df.columns)):\n",
        "        plt.plot(var_df[0], var_df[i], label=f'Parameter {i}')\n",
        "    \n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Parameter Value')\n",
        "    plt.title(f'Model {model_num} Parameter Evolution')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def display_final_parameters(model_data_dict):\n",
        "    \"\"\"Display final parameters for all models\"\"\"\n",
        "    # Create a DataFrame to hold parameters from all models\n",
        "    final_params = {}\n",
        "    param_names = [\"k1\", \"k2\", \"k3\", \"k4\", \"k5\", \"k6\", \"k7\", \"k8\", \"k9\", \"k10\", \"k11\", \"k12\"]\n",
        "    \n",
        "    for model_num, data in model_data_dict.items():\n",
        "        if data is None or \"variables\" not in data:\n",
        "            continue\n",
        "            \n",
        "        # Get the last row of variables (final parameters)\n",
        "        var_df = data[\"variables\"]\n",
        "        final_row = var_df.iloc[-1]\n",
        "        \n",
        "        # Skip the first column (iteration number)\n",
        "        params = final_row[1:].values\n",
        "        final_params[f\"Model {model_num}\"] = params\n",
        "    \n",
        "    # Create DataFrame with parameter names\n",
        "    num_params = max([len(p) for p in final_params.values()]) if final_params else 0\n",
        "    param_names = param_names[:num_params]\n",
        "    \n",
        "    df = pd.DataFrame(final_params)\n",
        "    df.index = param_names[:len(df)]\n",
        "    \n",
        "    # Display the table\n",
        "    display(HTML(\"<h3>Final Parameter Values for All Models</h3>\"))\n",
        "    display(df)\n",
        "    \n",
        "    # Save to CSV\n",
        "    df.to_csv(\"final_parameters.csv\")\n",
        "    print(\"Final parameters saved to final_parameters.csv\")\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Run Models (If Needed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_model(model_num):\n",
        "    \"\"\"Run a specific model by executing its notebook\"\"\"\n",
        "    print(f\"Checking if model {model_num} results exist...\")\n",
        "    \n",
        "    model_dir = f\"results/models/model{model_num}\"\n",
        "    if os.path.exists(model_dir) and os.path.exists(f\"{model_dir}/variables.dat\"):\n",
        "        print(f\"Model {model_num} results already exist. Skipping execution.\")\n",
        "        return True\n",
        "    \n",
        "    print(f\"Running model {model_num}...\")\n",
        "    try:\n",
        "        # For Colab, we need to get the notebook content from the repository\n",
        "        notebook_path = f\"notebooks/rompinnmodels_model{model_num}.ipynb\"\n",
        "        \n",
        "        if not os.path.exists(notebook_path):\n",
        "            print(f\"Notebook {notebook_path} not found.\")\n",
        "            return False\n",
        "        \n",
        "        # Create a temporary Python script from the notebook\n",
        "        import subprocess\n",
        "        subprocess.run([\"jupyter\", \"nbconvert\", \"--to\", \"python\", notebook_path, \"--output\", f\"temp_model{model_num}\"])\n",
        "        \n",
        "        # Modify the script to add necessary imports and path adjustments\n",
        "        with open(f\"temp_model{model_num}.py\", \"r\") as f:\n",
        "            script_content = f.read()\n",
        "        \n",
        "        # Add sys.path.append to ensure deepxdeAbeta can be imported\n",
        "        modified_script = \"import sys\\nsys.path.append('./src')\\n\" + script_content\n",
        "        \n",
        "        # Replace any references to binning_trials with results\n",
        "        modified_script = modified_script.replace(\"binning_trials/\", \"results/\")\n",
        "        \n",
        "        with open(f\"temp_model{model_num}.py\", \"w\") as f:\n",
        "            f.write(modified_script)\n",
        "        \n",
        "        # Run the modified script\n",
        "        subprocess.run([\"python\", f\"temp_model{model_num}.py\"])\n",
        "        \n",
        "        # Clean up\n",
        "        subprocess.run([\"rm\", f\"temp_model{model_num}.py\"])\n",
        "        \n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error running model {model_num}: {e}\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all models if needed\n",
        "for model_num in range(1, 9):\n",
        "    run_model(model_num)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Load and Analyze Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data for all models\n",
        "model_data_dict = {}\n",
        "for model_num in range(1, 9):\n",
        "    print(f\"Loading data for model {model_num}...\")\n",
        "    model_data = load_model_data(model_num)\n",
        "    if model_data is not None:\n",
        "        model_data_dict[model_num] = model_data\n",
        "        print(f\"✅ Model {model_num} data loaded successfully\")\n",
        "    else:\n",
        "        print(f\"❌ Failed to load data for model {model_num}\")\n",
        "\n",
        "print(f\"\\nLoaded data for {len(model_data_dict)} models\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Visualize Individual Model Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot loss history for each model\n",
        "for model_num, model_data in model_data_dict.items():\n",
        "    print(f\"\\n### Model {model_num} Loss History ###\")\n",
        "    plot_loss_history(model_num, model_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot parameter evolution for each model\n",
        "for model_num, model_data in model_data_dict.items():\n",
        "    print(f\"\\n### Model {model_num} Parameter Evolution ###\")\n",
        "    plot_parameter_evolution(model_num, model_data)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Combined Results Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display final parameters table for all models\n",
        "final_params_df = display_final_parameters(model_data_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot combined loss history for all models\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for model_num, model_data in model_data_dict.items():\n",
        "    if model_data is None or \"loss\" not in model_data:\n",
        "        continue\n",
        "        \n",
        "    loss_df = model_data[\"loss\"]\n",
        "    plt.semilogy(loss_df[0], loss_df[1], label=f'Model {model_num}')\n",
        "\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss (log scale)')\n",
        "plt.title('Combined Loss History for All Models')\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"-\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. Generate Final Comparison Figures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a heatmap of final parameters across models\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(final_params_df, annot=True, cmap=\"YlGnBu\", fmt=\".4f\")\n",
        "plt.title(\"Parameter Values Across Models\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the figure\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(final_params_df, annot=True, cmap=\"YlGnBu\", fmt=\".4f\")\n",
        "plt.title(\"Parameter Values Across Models\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"parameter_comparison_heatmap.png\")\n",
        "print(\"Saved parameter comparison heatmap to parameter_comparison_heatmap.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare final loss values across models\n",
        "final_loss = {}\n",
        "\n",
        "for model_num, model_data in model_data_dict.items():\n",
        "    if model_data is None or \"loss\" not in model_data:\n",
        "        continue\n",
        "        \n",
        "    loss_df = model_data[\"loss\"]\n",
        "    final_loss[f\"Model {model_num}\"] = loss_df[1].iloc[-1]\n",
        "\n",
        "loss_comparison_df = pd.DataFrame(list(final_loss.items()))\n",
        "loss_comparison_df.columns = [\"Model\", \"Final Loss\"]\n",
        "loss_comparison_df = loss_comparison_df.sort_values(\"Final Loss\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(loss_comparison_df[\"Model\"], loss_comparison_df[\"Final Loss\"])\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Final Loss Value\")\n",
        "plt.title(\"Final Loss Comparison Across Models\")\n",
        "plt.yscale(\"log\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "\n",
        "# Add value labels on top of bars\n",
        "for i, v in enumerate(loss_comparison_df[\"Final Loss\"]):\n",
        "    plt.text(i, v * 1.05, f\"{v:.6f}\", ha=\"center\", va=\"bottom\", rotation=90, fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(loss_comparison_df[\"Model\"], loss_comparison_df[\"Final Loss\"])\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Final Loss Value\")\n",
        "plt.title(\"Final Loss Comparison Across Models\")\n",
        "plt.yscale(\"log\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "for i, v in enumerate(loss_comparison_df[\"Final Loss\"]):\n",
        "    plt.text(i, v * 1.05, f\"{v:.6f}\", ha=\"center\", va=\"bottom\", rotation=90, fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"final_loss_comparison.png\")\n",
        "print(\"Saved final loss comparison to final_loss_comparison.png\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 9. Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display summary statistics\n",
        "print(\"# Summary of Model Results\")\n",
        "print(f\"Number of models analyzed: {len(model_data_dict)}\")\n",
        "\n",
        "if loss_comparison_df is not None and not loss_comparison_df.empty:\n",
        "    best_model = loss_comparison_df.iloc[0][\"Model\"]\n",
        "    best_loss = loss_comparison_df.iloc[0][\"Final Loss\"]\n",
        "    print(f\"Best performing model: {best_model} with final loss: {best_loss:.6f}\")\n",
        "\n",
        "print(\"\\nFinal parameter values have been saved to final_parameters.csv\")\n",
        "print(\"Comparison figures have been saved as PNG files\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
